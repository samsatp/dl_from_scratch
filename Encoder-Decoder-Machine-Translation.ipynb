{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebb1dad",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Interface\n",
    "\n",
    "Encoder encodes input sequence into context variable ($\\mathbf c$)\n",
    "\n",
    "$\\text{Encoder}$\n",
    "> $\\text{RNN with } n \\text{ layers}, k \\text{ hidden units} $ <br>\n",
    "> $\\text{input sequence: } \\mathbf{X = (x_1,  .., x_T)} \\in \\mathbb{R}^{(, T, emb\\_size)}$ <br><br>\n",
    "> $\\text{RNN output sequences: } \\mathbf{(h_{1,n}, ..,h_{T,n})} \\in \\mathbb{R}^{(, T, k)}$ <br>\n",
    "> $\\text{RNN output states: } \\mathbf{(h_{T,1}, ..,h_{T,n})} \\in \\mathbb{R}^{(, n, k)}$\n",
    "\n",
    "$\\text{context variable: } \\mathbf{c = q(h_{1,n}, ..,h_{T,n}) = h_{T,n}} \\in \\mathbb{R}^{(, k)}$\n",
    "\n",
    "$\\text{Decoder}$\n",
    "> $\\text{RNN initial state: } \\mathbf{(h_{T,1}, ..,h_{T,n})}$ <br>\n",
    "> $\\text{input during training: } \\mathbf{X = [c ; embed(y_{T\\prime -1})]} \\in \\mathbb{R}^{(, 1, k + dec\\_emb\\_size)}$ <br>\n",
    "> $\\text{input during prediction: } \\mathbf{X = [ c ; embed(\\hat{y}_{T\\prime -1})]}$ <br>\n",
    "> $\\text{where } \\mathbf{X_{T\\prime = 0} = [c ; embed(\\text{<bos>})]}$<br><br>\n",
    "> $\\text{RNN outputs: } \\mathbf{k} \\in \\mathbb{R}^{(, 1, dec\\_num\\_hiddens)}$ <br>\n",
    "> $\\text{outputs: } \\mathbf{\\hat{y}_{t\\prime}} \\in \\mathbb{R}^{(, 1, vocab\\_size)}$\n",
    "\n",
    "The output is the *Logits* distribution of next token prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73cd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, X, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, X, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def init_state(self, encoder_outputs, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ca9373ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.preprocess_fn = kwargs.get(\"preprocess_fn\")\n",
    "    \n",
    "    def call(self, enc_X, dec_X, *args, **kwargs):\n",
    "        enc_outputs = self.encoder(enc_X,  *args, **kwargs)\n",
    "        decoder_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        \n",
    "        return self.decoder(dec_X, decoder_state, **kwargs)\n",
    "    \n",
    "    def train(self,):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def preprocess(self, X):\n",
    "        if self.preprocess_fn:\n",
    "            return self.preprocess_fn(X)\n",
    "        else:\n",
    "            return X.lower().split()\n",
    "    \n",
    "    def predict(self, src_inputs, src_vocab, tgt_vocab, num_steps):\n",
    "        src_inputs_tokens = self.preprocess(src_inputs)\n",
    "        src_tokens = src_vocab[ src_inputs_tokens ] + [ src_vocab['<eos>'] ]\n",
    "        \n",
    "        #enc_valid_len = tf.constant([len(src_tokens)])\n",
    "        \n",
    "        if tf.rank(src_inputs) < 2:  # [1, 7, 3, 14] : (T)\n",
    "            enc_X = tf.expand_dims(src_tokens, axis=0)  # (, T)\n",
    "            dec_X = tf.expand_dims(tf.constant([tgt_vocab['<bos>']]), axis=0)\n",
    "                        \n",
    "        enc_outputs = self.encoder(enc_X, training=False)   # to get context variables\n",
    "        dec_state   = self.decoder.init_state(enc_outputs)  # init state once\n",
    "        \n",
    "        output_seq = []\n",
    "        for _ in range(num_steps):\n",
    "            Y, dec_state = self.decoder(dec_X, dec_state, training=False)\n",
    "            dec_X = tf.argmax(Y, axis=-1)\n",
    "            pred = tf.squeeze(dec_X, axis=0)\n",
    "            \n",
    "            if pred == tgt_vocab['<eos>']:\n",
    "                break\n",
    "            output_seq.append(pred.numpy())\n",
    "            \n",
    "        return ' '.join(tgt_vocab.to_tokens(tf.reshape(output_seq, shape = -1).numpy().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e124e",
   "metadata": {},
   "source": [
    "## Seq2seq model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd293929",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "At each timestep of encoder $t$,\n",
    "\n",
    "$$h_t = f(x_t, h_{t-1})$$\n",
    "\n",
    "Then, the context variable from encoder is\n",
    "$$c = q(h_1,...,h_T)$$\n",
    "where $h_t$ is hidden states at timestep $t$ of all layers.\n",
    "\n",
    "> We'll use $c = q(h_1,...,h_T) = h_T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8d695950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq_Encoder(Encoder):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.embed = tf.keras.layers.Embedding(input_dim = vocab_size, output_dim = embed_size)\n",
    "        self.rnn   = tf.keras.layers.RNN(\n",
    "            tf.keras.layers.StackedRNNCells(\n",
    "                [\n",
    "                    tf.keras.layers.GRUCell(units = num_hiddens, dropout = dropout)\n",
    "                    for _ in range(num_layers)\n",
    "                ]\n",
    "            ),\n",
    "            name='Encoder_RNN',\n",
    "            return_sequences=True,  ## True: return full output sequence, False: return last output sequence\n",
    "            return_state=True       ## True: return all hidden state\n",
    "        )\n",
    "        \n",
    "    def call(self, X, *args, **kwargs):\n",
    "        assert tf.rank(X) == 2                    # (batch_size, timesteps)\n",
    "        emb_vector = self.embed(X)                # (batch_size, timesteps, emb_dim)\n",
    "        output = self.rnn(emb_vector,  **kwargs)  # (batch_size, timesteps, num_hiddens)\n",
    "        \n",
    "        return {'sequences': output[0], 'states': output[1:]}  \n",
    "    ## the hidden states of the last layer at all the time steps, (sequences)\n",
    "    ## (for GRU) hidden state of last time step of each layer     (states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96811cc5",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "$\\mathbf S: $ `(num_encRnn_layers, num_encRnn_hiddens)`  ; All last hidden state from encoder\n",
    "\n",
    "$C = S[-1] $ : `(1, num_encRnn_hiddens)` ; last hidden state of last layer (according to $q$)\n",
    "\n",
    "At each timstep of decoder $t^{\\prime}$, \n",
    "\n",
    "#### 1) Training\n",
    "\n",
    "$X_{t^{\\prime}} = Y_{t^{\\prime}-1}$ : `(batch_size, max_steps)`  ; decoder input when training is $Y_{t^{\\prime}-1}$ where $X_{t^{\\prime} = 0} = \\text{<bos>}$\n",
    "\n",
    "$\\text{decoder input} = [\\text{embed}(X_{t^{\\prime}})  ;  C]$ :  `(batch_size, max_steps, emb_size + C.shape[0])`\n",
    "\n",
    "$\\text{decoder initial state} = S$ : `(num_layers, num_hiddens)` ; the same in both encoder and decoder\n",
    "\n",
    "___\n",
    "#### 2) Prediction\n",
    "$X_{t^{\\prime}} = \\hat{Y}_{t^{\\prime}-1}$ : `(batch_size, 1)`\n",
    "\n",
    "$\\text{decoder input} = [\\text{embed}(X_{t^{\\prime}}) ; C]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1a597a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq_Decoder(Decoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed = tf.keras.layers.Embedding(input_dim = vocab_size, output_dim = embed_size)\n",
    "        self.rnn   = tf.keras.layers.RNN(\n",
    "            tf.keras.layers.StackedRNNCells([\n",
    "                tf.keras.layers.GRUCell(units = num_hiddens, dropout = dropout) \n",
    "                for _ in range(num_layers)\n",
    "            ]),\n",
    "            name = 'Decoder_RNN',\n",
    "            return_sequences = True,\n",
    "            return_state = True\n",
    "        )\n",
    "        self.dense = tf.keras.layers.Dense(units = vocab_size)\n",
    "        \n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        last_h_of_EachLayer = enc_outputs['states']\n",
    "        return last_h_of_EachLayer  # return last-step hidden state of all layer \n",
    "        \n",
    "    def call(self, X, state, **kwargs):  ## X : (batch_size, max_steps) and state : (1, num_encRnn_hiddens)\n",
    "        X = self.embed(X)  ## X : (batch_size, max_steps, emb_size)\n",
    "        \n",
    "        ## construct Decoder input : (batch_size, max_steps, emb_size + last_state.shape[1])\n",
    "        max_steps = X.shape[1]\n",
    "        context = tf.repeat(tf.expand_dims(state[-1], axis=1), repeats=max_steps, axis=1)\n",
    "        dec_input = tf.concat([X, context], axis=2)\n",
    "        \n",
    "        ## Forward pass: pass hidden state from rnn to Dense\n",
    "        rnn_output, *rnn_states = self.rnn(inputs=dec_input, initial_state=state)\n",
    "        \n",
    "        output = self.dense(rnn_output)   ## output : (batch_size, vocab_size)\n",
    "        \n",
    "        return output, rnn_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d382dd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.zeros((4, 7))\n",
    "encoder = Seq2Seq_Encoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
    "decoder = Seq2Seq_Decoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
    "\n",
    "state = decoder.init_state(encoder(X))\n",
    "output = decoder(X, state, training=False)\n",
    "\n",
    "output_sequence = output[0]\n",
    "output_states = output[1:]\n",
    "\n",
    "print(output_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1bd20391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, TensorShape([4, 16]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state), state[0].shape   ## num_layers, batch_size, num_hiddens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa95f4",
   "metadata": {},
   "source": [
    "### Masked loss function\n",
    "If pad 0 at the very begining, this step can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "691d21e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[1, 0, 0],\n",
       "       [4, 5, 0]])>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"Mask irrelevant entries in sequences.\"\"\"\n",
    "    maxlen = X.shape[1]\n",
    "    mask = tf.range(start=0, limit=maxlen, dtype=tf.float32)[\n",
    "        None, :] < tf.cast(valid_len[:, None], dtype=tf.float32)\n",
    "\n",
    "    if len(X.shape) == 3:\n",
    "        return tf.where(tf.expand_dims(mask, axis=-1), X, value)\n",
    "    else:\n",
    "        return tf.where(mask, X, value)\n",
    "\n",
    "X = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "sequence_mask(X, tf.constant([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1a6f41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class MaskedSoftmaxCELoss(tf.keras.losses.Loss):\n",
    "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
    "    def __init__(self, valid_len):\n",
    "        super().__init__(reduction='none')\n",
    "        self.valid_len = valid_len\n",
    "\n",
    "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "    # `label` shape: (`batch_size`, `num_steps`)\n",
    "    # `valid_len` shape: (`batch_size`,)\n",
    "    def call(self, label, pred):\n",
    "        weights = tf.ones_like(label, dtype=tf.float32)\n",
    "        weights = sequence_mask(weights, self.valid_len)\n",
    "        \n",
    "        label_one_hot = tf.one_hot(label, depth=pred.shape[-1])\n",
    "        unweighted_loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits=True, reduction='none')(label_one_hot, pred)\n",
    "        weighted_loss = tf.reduce_mean((unweighted_loss*weights), axis=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "254760c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.3025851, 1.1512926, 0.       ], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = MaskedSoftmaxCELoss(tf.constant([4, 2, 0]))\n",
    "loss(tf.ones((3,4), dtype = tf.int32), tf.ones((3, 4, 10))).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ffc9c6",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "72ac834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import tensorflow as d2l\n",
    "batch_size, num_steps = 64, 10\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9a2f41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        losses = []\n",
    "        for batch in data_iter:\n",
    "            X, X_valid_len, Y, Y_valid_len = batch\n",
    "                ## X : (batch_size, max_steps)\n",
    "                ## Y : (batch_size, len_target)\n",
    "            \n",
    "            # prepare <bos> as the first token for every row in this batch\n",
    "            bos = tf.reshape(\n",
    "                    tf.constant([tgt_vocab['<bos>']] * Y.shape[0]),\n",
    "                    shape=(-1, 1)\n",
    "                    )\n",
    "            # dec_input(row=1) : [<bos>, Y(row=1)[1], Y(row=1)[2], ..., Y(row=1)[t-1] ]\n",
    "            dec_input = tf.concat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                Y_hat, _ = net(X, dec_input, training=True)\n",
    "                l = MaskedSoftmaxCELoss(Y_valid_len)(Y, Y_hat)\n",
    "                losses.append(tf.reduce_mean(l).numpy())\n",
    "            \n",
    "            gradients = tape.gradient(l, net.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, net.trainable_variables))\n",
    "            \n",
    "\n",
    "        if epoch % 20 ==0: print(f'epoch {epoch} / loss ', np.array(losses).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e79d0579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  2.027305\n",
      "loss  0.82422286\n",
      "loss  0.64376575\n",
      "loss  0.5360762\n",
      "loss  0.46055856\n",
      "loss  0.39579645\n",
      "loss  0.3565399\n",
      "loss  0.32139468\n",
      "loss  0.29013962\n",
      "loss  0.26653638\n",
      "loss  0.23823926\n",
      "loss  0.21936655\n",
      "loss  0.20713994\n",
      "loss  0.19158502\n",
      "loss  0.17577311\n"
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 300, d2l.try_gpu()\n",
    "\n",
    "encoder = Seq2Seq_Encoder( len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2Seq_Decoder( len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2e34fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . = va !\n",
      "i lost . = .\n",
      "he's calm . = il est malade .\n",
      "i'm home . = qui <unk> .\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation = net.predict(eng, src_vocab, tgt_vocab, num_steps)\n",
    "    print(eng,'=', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef6bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
