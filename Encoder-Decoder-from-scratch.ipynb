{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96c2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "from d2l import tensorflow as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8ac6b",
   "metadata": {},
   "source": [
    "## 1. Load text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "620e3d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# text lines: 3221\n",
      "the time machine by h g wells\n",
      "twinkled and his usually pale face was flushed and animated the\n"
     ]
    }
   ],
   "source": [
    "d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt',\n",
    "                                '090b5e7e70c295757f55df93cb0a180b9691891a')\n",
    "\n",
    "def read_time_machine():  #@save\n",
    "    \"\"\"Load the time machine dataset into a list of text lines.\"\"\"\n",
    "    with open(d2l.download('time_machine'), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
    "\n",
    "lines = read_time_machine()\n",
    "print(f'# text lines: {len(lines)}')\n",
    "print(lines[0])\n",
    "print(lines[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba55ed2",
   "metadata": {},
   "source": [
    "## 2. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7772a50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'h', 'e', ' ', 't', 'i', 'm', 'e', ' ', 'm', 'a', 'c', 'h', 'i', 'n', 'e', ' ', 'b', 'y', ' ', 'h', ' ', 'g', ' ', 'w', 'e', 'l', 'l', 's']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['i']\n",
      "[]\n",
      "[]\n",
      "['t', 'h', 'e', ' ', 't', 'i', 'm', 'e', ' ', 't', 'r', 'a', 'v', 'e', 'l', 'l', 'e', 'r', ' ', 'f', 'o', 'r', ' ', 's', 'o', ' ', 'i', 't', ' ', 'w', 'i', 'l', 'l', ' ', 'b', 'e', ' ', 'c', 'o', 'n', 'v', 'e', 'n', 'i', 'e', 'n', 't', ' ', 't', 'o', ' ', 's', 'p', 'e', 'a', 'k', ' ', 'o', 'f', ' ', 'h', 'i', 'm']\n",
      "['w', 'a', 's', ' ', 'e', 'x', 'p', 'o', 'u', 'n', 'd', 'i', 'n', 'g', ' ', 'a', ' ', 'r', 'e', 'c', 'o', 'n', 'd', 'i', 't', 'e', ' ', 'm', 'a', 't', 't', 'e', 'r', ' ', 't', 'o', ' ', 'u', 's', ' ', 'h', 'i', 's', ' ', 'g', 'r', 'e', 'y', ' ', 'e', 'y', 'e', 's', ' ', 's', 'h', 'o', 'n', 'e', ' ', 'a', 'n', 'd']\n",
      "['t', 'w', 'i', 'n', 'k', 'l', 'e', 'd', ' ', 'a', 'n', 'd', ' ', 'h', 'i', 's', ' ', 'u', 's', 'u', 'a', 'l', 'l', 'y', ' ', 'p', 'a', 'l', 'e', ' ', 'f', 'a', 'c', 'e', ' ', 'w', 'a', 's', ' ', 'f', 'l', 'u', 's', 'h', 'e', 'd', ' ', 'a', 'n', 'd', ' ', 'a', 'n', 'i', 'm', 'a', 't', 'e', 'd', ' ', 't', 'h', 'e']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(lines, token='word'):  #@save\n",
    "    \"\"\"Split text lines into word or character tokens.\"\"\"\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('ERROR: unknown token type: ' + token)\n",
    "\n",
    "tokens = tokenize(lines, token='char')\n",
    "for i in range(11):\n",
    "    print(tokens[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da784ce1",
   "metadata": {},
   "source": [
    "## 3. Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61026d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Vocab:\n",
    "    '''\n",
    "        Vacab extract `vocabulary` from given tokens (List[List[str]])\n",
    "    '''\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "            \n",
    "        self._token_freqs = self._get_token_freqs(tokens)\n",
    "        self.idx_to_token = [\"<unk>\"] + reserved_tokens\n",
    "        self.token_to_idx = {self.idx_to_token[idx]: idx for idx in range(len(self))}\n",
    "        \n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq: break\n",
    "                \n",
    "            if token not in self.idx_to_token:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self)-1\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''\n",
    "            Vocab_size\n",
    "        '''\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def _get_token_freqs(self, tokens_list: List[List[str]]):\n",
    "        '''\n",
    "            get dict {token (str): amount_of_token}\n",
    "        '''\n",
    "        assert isinstance(tokens_list, list) and isinstance(tokens_list[0], list) and isinstance(tokens_list[0][0], str)\n",
    "        \n",
    "        tokens = []\n",
    "        for line in tokens_list:\n",
    "            for token in line:\n",
    "                tokens.append(token)\n",
    "        tokens_count = collections.Counter(tokens).items()\n",
    "        return sorted(tokens_count, key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    def to_tokens(self, idx):\n",
    "        '''\n",
    "            convert indices (int) to token (str)\n",
    "        '''\n",
    "        if isinstance(idx, int):\n",
    "            return self.idx_to_token[idx]\n",
    "        \n",
    "        return [self.idx_to_token[i] for i in idx]\n",
    "    \n",
    "    def __getitem__(self, tokens):\n",
    "        '''\n",
    "            convert token (str) to indices (int)\n",
    "        '''\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "        \n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs\n",
    "    \n",
    "    @property\n",
    "    def unk(self):\n",
    "        return self.token_to_idx['<unk>']\n",
    "    \n",
    "    @property\n",
    "    def get_vocab(self):\n",
    "        return self.idx_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51b59bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Vocab(tokens)\n",
    "vocab['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34103462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.to_tokens(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9393fe51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)  # vocab size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf1ba7",
   "metadata": {},
   "source": [
    "## 4. Create load data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a74d81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "class SeqDataLoader:\n",
    "    def __init__(self, batch_size, num_steps, tokens: List[List[str]], use_random_iter=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "        self.vocab = Vocab(tokens)\n",
    "        self.corpus = [token for line in tokens for token in line]\n",
    "        \n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn = self.seq_data_iter_random\n",
    "        else:\n",
    "            self.data_iter_fn = self.seq_data_iter_sequential\n",
    "            \n",
    "    def seq_data_iter_random(self, corpus, batch_size, num_steps): \n",
    "        '''\n",
    "            Generator to generate X, Y with both shape (batch_size, num_steps) \n",
    "            Each X, Y sequence is randomly selected\n",
    "        '''\n",
    "        num_subseqs = (len(corpus) - 1) // num_steps\n",
    "        initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "        \n",
    "        random.shuffle(initial_indices)\n",
    "        \n",
    "        get_data = lambda pos: corpus[pos: pos+num_steps]\n",
    "        num_batchs = num_subseqs // batch_size\n",
    "        \n",
    "        for i in range(0, batch_size * num_batches, batch_size):\n",
    "        \n",
    "            initial_indices_per_batch = initial_indices[i: i + batch_size]\n",
    "            X = [data(j) for j in initial_indices_per_batch]\n",
    "            Y = [data(j + 1) for j in initial_indices_per_batch]\n",
    "            yield tf.constant(X), tf.constant(Y)\n",
    "            \n",
    "    def seq_data_iter_sequential(self, corpus, batch_size, num_steps): \n",
    "        '''\n",
    "            Generator to generate X, Y with both shape (batch_size, num_steps) \n",
    "            Each X, Y sequence is collected in the original order\n",
    "        '''\n",
    "        offset = 0\n",
    "        num_tokens = ((len(corpus) - 1) // batch_size) * batch_size\n",
    "        \n",
    "        Xs = tf.constant(corpus[offset: offset + num_tokens])\n",
    "        Ys = tf.constant(corpus[offset + 1: offset + 1 + num_tokens])\n",
    "        Xs = tf.reshape(Xs, (batch_size, -1))\n",
    "        Ys = tf.reshape(Ys, (batch_size, -1))\n",
    "        num_batches = Xs.shape[1] // num_steps\n",
    "        for i in range(0, num_batches * num_steps, num_steps):\n",
    "            X = Xs[:, i: i + num_steps]\n",
    "            Y = Ys[:, i: i + num_steps]\n",
    "            yield X, Y\n",
    "            \n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90e1c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_time_machine(batch_size, num_steps, tokens,\n",
    "                           use_random_iter=False, max_tokens=10000):\n",
    "    \"\"\"Return the iterator and the vocabulary of the time machine dataset.\"\"\"\n",
    "    data_iter = SeqDataLoader( batch_size, num_steps, tokens)\n",
    "    return data_iter, data_iter.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74b416c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab_iter = load_data_time_machine( batch_size, num_steps, tokens )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04b159cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[b't' b'h' b'e' ... b'e' b' ' b't']\n",
      " [b' ' b'c' b'a' ... b'n' b'd' b' ']\n",
      " [b's' b' ' b'h' ... b'a' b't' b'u']\n",
      " ...\n",
      " [b'h' b'r' b'e' ... b'u' b't' b' ']\n",
      " [b't' b' ' b'l' ... b's' b' ' b'o']\n",
      " [b't' b'h' b'e' ... b'o' b's' b's']], shape=(32, 35), dtype=string)\n",
      "tf.Tensor(\n",
      "[[b'i' b'm' b'e' ... b'c' b'o' b'n']\n",
      " [b'l' b'e' b'f' ... b'a' b'r' b'd']\n",
      " [b's' b'i' b's' ... b'o' b'r' b' ']\n",
      " ...\n",
      " [b'o' b'f' b' ' ... b' ' b'i' b' ']\n",
      " [b'f' b' ' b'h' ... b'n' b't' b' ']\n",
      " [b' ' b'u' b'p' ... b'i' b'l' b' ']], shape=(32, 35), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for X, Y in train_iter:\n",
    "    print(X)\n",
    "    i+=1\n",
    "    if i == 2: break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "24d3123a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 35]), TensorShape([32, 35]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ede59a",
   "metadata": {},
   "source": [
    "## 5. Model init\n",
    "\n",
    "$$X : \\text{intput with shape (timesteps, batch_size, vocab_size)}$$\n",
    "\n",
    "$\\text{At each timestep,}$\n",
    "\n",
    "$\\text{X} = [X ; H]$ ; (batch_size, vocab_size + hidden)\n",
    "\n",
    "$H = \\phi (X W_h+ b_h)$ ; (batch_size, hidden)\n",
    "\n",
    "$O = W_q H + b_q$ ; (batch_size, num_outputs)\n",
    "\n",
    "$\\text{Thus, for all timesteps in 1 minibatch we get (timestep * batch_size, num_outputs) }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3a7ac2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModelScratch:\n",
    "    \n",
    "    def __init__(self, vocab_size, num_hiddens, initial_state_fn):\n",
    "        \n",
    "        self.initial_state_fn = initial_state_fn\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_hiddens = num_hiddens\n",
    "        \n",
    "        num_outputs = vocab_size\n",
    "        \n",
    "        normal = lambda shape: tf.random.normal(shape=shape, stddev=0.01, mean=0, dtype=tf.float32)\n",
    "        \n",
    "        self.W_h = tf.Variable(normal(shape = (vocab_size + num_hiddens, num_hiddens)), dtype=tf.float32)\n",
    "        self.b_h = tf.Variable(normal(shape = (num_hiddens, )) , dtype=tf.float32)\n",
    "        self.W_hq= tf.Variable(normal(shape = (num_hiddens, num_outputs)), dtype=tf.float32)\n",
    "        self.b_q = tf.Variable(normal(shape = (num_outputs, )), dtype=tf.float32)\n",
    "        \n",
    "    \n",
    "    def forward_fn(self, inputs, state):\n",
    "        \"\"\"\n",
    "            inputs: 1 minibatch = (timesteps, batch_size, vocab_size)\n",
    "        \"\"\"\n",
    "        outputs = []   # outputs of this batch\n",
    "        H = state\n",
    "        for X in inputs:   # for each timestep                 ; X = (batch_size, vocab_size)\n",
    "            X = tf.concat([X, H], axis=1)                      # X = (batch_size, vocab_size + hidden)\n",
    "            H = tf.tanh( tf.matmul(X, self.W_h) + self.b_h )   # H = (batch_size, hidden)\n",
    "            O = tf.matmul(H, self.W_hq) + self.b_q             # O = (batch_size, num_outputs)\n",
    "            outputs.append(O)\n",
    "        return tf.concat(outputs, axis=0), H                   # y_pred = (timesteps * batch_size, num_outputs)\n",
    "    \n",
    "    def __call__(self, X, state):\n",
    "        return self.forward_fn(X, state)\n",
    "    \n",
    "    def begin_state(self, batch_size):\n",
    "        \"\"\"\n",
    "            this fn initialize and return initial state\n",
    "        \"\"\"\n",
    "        return self.initial_state_fn(batch_size, self.num_hiddens)\n",
    "        \n",
    "    def _get_params(self):\n",
    "        return [self.W_h, self.b_h, self.W_hq, self.b_q]\n",
    "    \n",
    "    @property\n",
    "    def trainables(self):\n",
    "        return self._get_params()\n",
    "        \n",
    "    @property\n",
    "    def get_state(self):\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3404fde",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c312c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = 512\n",
    "batch_size = 2\n",
    "num_steps  = 1\n",
    "\n",
    "initial_state_fn = lambda batch_size, num_hiddens: tf.zeros((batch_size, num_hiddens), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "54075fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0d652ace",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.shape : (2, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 28]), TensorShape([2, 512]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = RNNModelScratch(\n",
    "    vocab_size = len(vocab), \n",
    "    num_hiddens = 512, \n",
    "    initial_state_fn = initial_state_fn\n",
    ")\n",
    "initial_state = net.begin_state(batch_size)\n",
    "\n",
    "X = tf.random.normal(shape=(num_steps, batch_size, len(vocab)))\n",
    "Y, new_state = net(X, initial_state)\n",
    "\n",
    "Y.shape, new_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0364c",
   "metadata": {},
   "source": [
    "## 6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "22c0a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_hiddens = 512\n",
    "\n",
    "net = RNNModelScratch(len(vocab), num_hiddens, initial_state_fn=initial_state_fn)\n",
    "initial_state = net.begin_state(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6f3e6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prefix, net, num_preds, vocab):\n",
    "    state = net.begin_state(batch_size=1)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    \n",
    "    def get_inputs():\n",
    "        return tf.one_hot( tf.reshape(outputs[-1], (1,1)), len(vocab))\n",
    "    \n",
    "    ## Accumulate information from all prefix\n",
    "    for y in prefix[1:]:\n",
    "        _, state = net(get_inputs(), state)\n",
    "        outputs.append(vocab[y])\n",
    "        \n",
    "    ## Make prediction\n",
    "    for _ in range(num_preds):\n",
    "        y, state = net(get_inputs(), state)\n",
    "        y_pred = tf.argmax(y, axis=1)[0].numpy()\n",
    "        \n",
    "        outputs.append(y_pred)\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3cdde06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time traveller <unk>sssssssss'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = RNNModelScratch(len(vocab), num_hiddens=512, initial_state_fn=initial_state_fn)\n",
    "O = predict('time traveller ', net, 10, vocab)\n",
    "\n",
    "''.join([vocab.idx_to_token[i] for i in O])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32161c98",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4d271b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10)\n",
      "(32, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_steps = 10\n",
    "train_iter, vocab_iter = d2l.load_data_time_machine(\n",
    "    batch_size, num_steps, use_random_iter=False)\n",
    "\n",
    "for X, Y in train_iter:\n",
    "    print(X.shape)   # (batch_size, num_steps)\n",
    "    print(Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2290da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(grads, theta):  #@save\n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    theta = tf.constant(theta, dtype=tf.float32)\n",
    "    new_grad = []\n",
    "    for grad in grads:\n",
    "        if isinstance(grad, tf.IndexedSlices):\n",
    "            new_grad.append(tf.convert_to_tensor(grad))\n",
    "        else:\n",
    "            new_grad.append(grad)\n",
    "    norm = tf.math.sqrt(sum((tf.reduce_sum(grad ** 2)).numpy()\n",
    "                        for grad in new_grad))\n",
    "    norm = tf.cast(norm, tf.float32)\n",
    "    if tf.greater(norm, theta):\n",
    "        for i, grad in enumerate(new_grad):\n",
    "            new_grad[i] = grad * theta / norm\n",
    "    else:\n",
    "        new_grad = new_grad\n",
    "    return new_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3d07b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_epoch_ch8(net, train_iter, loss_fn, updater, use_random_iter):\n",
    "    \n",
    "    def get_inputs(X):\n",
    "        X = tf.one_hot(X, len(vocab))        # X = (batch_size, timesteps, vocab_size)\n",
    "        X = tf.transpose(X, perm=[1, 0, 2])  # X = (timesteps,  batch_size,vacab_size)\n",
    "        return X\n",
    "    \n",
    "    state = None\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:   ## If random_iter -> init state at every batch/ If seq_iter -> state can accumulate information over full epoch\n",
    "            state = net.begin_state(batch_size=X.shape[0])\n",
    "            \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            y_pred, state = net(get_inputs(X), state)    # y_pred = (timesteps * batch_size, vocab_size)\n",
    "            y = tf.reshape(tf.transpose(Y), (-1))        # Y = (batch_size, timesteps) -> y = (timestep * batch_size)\n",
    "            loss = loss_fn(y_true = y, y_pred=y_pred)\n",
    "            \n",
    "        params = net.trainables\n",
    "        grads = tape.gradient(loss, params)\n",
    "        updater.apply_gradients(zip(grads, params))\n",
    "        \n",
    "        metric.add(loss * d2l.size(y), d2l.size(y))\n",
    "    return np.exp(metric[0] / metric[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "59765a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, use_random_iter=False):\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    updater = tf.keras.optimizers.SGD(lr)\n",
    "    \n",
    "    get_predict = lambda prefix: predict(prefix, net, 50, vocab)\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        ppl = train_epoch_ch8(net, train_iter, loss, updater, use_random_iter)\n",
    "        \n",
    "        if (e + 1) % 10 == 0:\n",
    "            print(get_predict('time traveller'))\n",
    "        print(f'perplexity {ppl:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7dc8df33",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity 19.7\n",
      "perplexity 16.5\n",
      "perplexity 13.7\n",
      "perplexity 11.9\n",
      "perplexity 11.1\n",
      "perplexity 10.6\n",
      "perplexity 10.3\n",
      "perplexity 9.9\n",
      "perplexity 9.7\n",
      "[3, 5, 13, 2, 1, 3, 10, 4, 22, 2, 12, 12, 2, 10, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1, 3, 9, 2, 1]\n",
      "perplexity 9.5\n",
      "perplexity 9.4\n",
      "perplexity 9.1\n",
      "perplexity 9.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [167]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs, lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m net \u001b[38;5;241m=\u001b[39m RNNModelScratch(\u001b[38;5;28mlen\u001b[39m(vocab), num_hiddens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, initial_state_fn\u001b[38;5;241m=\u001b[39minitial_state_fn)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrain_ch8\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [166]\u001b[0m, in \u001b[0;36mtrain_ch8\u001b[1;34m(net, train_iter, vocab, lr, num_epochs, use_random_iter)\u001b[0m\n\u001b[0;32m      5\u001b[0m get_predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m prefix: predict(prefix, net, \u001b[38;5;241m50\u001b[39m, vocab)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 8\u001b[0m     ppl \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch_ch8\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_random_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (e \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(get_predict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime traveller\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Input \u001b[1;32mIn [165]\u001b[0m, in \u001b[0;36mtrain_epoch_ch8\u001b[1;34m(net, train_iter, loss_fn, updater, use_random_iter)\u001b[0m\n\u001b[0;32m     19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_true \u001b[38;5;241m=\u001b[39m y, y_pred\u001b[38;5;241m=\u001b[39my_pred)\n\u001b[0;32m     21\u001b[0m params \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mtrainables\n\u001b[1;32m---> 22\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m updater\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, params))\n\u001b[0;32m     25\u001b[0m metric\u001b[38;5;241m.\u001b[39madd(loss \u001b[38;5;241m*\u001b[39m d2l\u001b[38;5;241m.\u001b[39msize(y), d2l\u001b[38;5;241m.\u001b[39msize(y))\n",
      "File \u001b[1;32mc:\\users\\samsa\\downloads\\d2l-en\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1084\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_gradients \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1081\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1082\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(output_gradients)]\n\u001b[1;32m-> 1084\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1093\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\users\\samsa\\downloads\\d2l-en\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:71\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\samsa\\downloads\\d2l-en\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:159\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    157\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mc:\\users\\samsa\\downloads\\d2l-en\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1745\u001b[0m, in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_b:\n\u001b[0;32m   1744\u001b[0m   grad_a \u001b[38;5;241m=\u001b[39m gen_math_ops\u001b[38;5;241m.\u001b[39mmat_mul(grad, b, transpose_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1745\u001b[0m   grad_b \u001b[38;5;241m=\u001b[39m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmat_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m t_b:\n\u001b[0;32m   1747\u001b[0m   grad_a \u001b[38;5;241m=\u001b[39m gen_math_ops\u001b[38;5;241m.\u001b[39mmat_mul(grad, b)\n",
      "File \u001b[1;32mc:\\users\\samsa\\downloads\\d2l-en\\tensorflow\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6012\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   6011\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6012\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6013\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMatMul\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranspose_a\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranspose_b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6014\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   6016\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 500, 1\n",
    "net = RNNModelScratch(len(vocab), num_hiddens=512, initial_state_fn=initial_state_fn)\n",
    "\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f12552e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 32), dtype=int32, numpy=\n",
       "array([[15, 21,  1, 10,  4,  4, 19,  3, 12,  5, 12, 20,  3, 19,  8,  7,\n",
       "         2,  4, 15,  9,  3, 18,  7, 12,  9,  7,  2, 19,  1, 10,  6, 13],\n",
       "       [ 9, 14, 16,  4, 14,  6,  1,  7,  2,  7,  2, 10,  9,  7,  1, 17,\n",
       "         1, 10,  1,  2,  9,  7,  1,  2,  4, 16, 10,  2, 16,  1,  2,  3],\n",
       "       [ 5, 21,  7,  3, 18,  1,  7, 14, 10, 14,  6,  7,  2, 14,  7,  8,\n",
       "        17,  2, 26, 10,  2,  1, 14, 10, 12,  1, 13,  8,  4,  9,  1,  9],\n",
       "       [ 6, 21, 10,  9,  9,  5, 16, 10,  1,  8, 18, 16, 19,  1, 16,  1,\n",
       "         4,  1, 14,  2,  1, 21, 20, 19, 12,  3,  4,  1,  5,  2,  8,  2],\n",
       "       [ 2, 12,  2,  2,  3,  6,  1,  1, 17,  6,  3,  2,  1,  5,  1,  3,\n",
       "         8, 19, 13,  3,  2,  4,  1,  7,  1,  9,  6,  8,  6,  1, 14,  6],\n",
       "       [ 1,  2, 16, 10,  1,  8,  3, 15,  5,  2,  9,  8, 15,  1,  9,  9,\n",
       "         1,  7, 20,  9,  4, 15,  4, 14,  3,  2,  1,  7,  3,  9, 21,  1],\n",
       "       [21,  8,  5,  1, 19,  3,  9,  7,  3,  8, 21,  8,  7,  9,  5,  2,\n",
       "         4, 14,  5,  2, 10, 23, 18,  1, 10,  1,  8,  1, 12,  4,  8,  9],\n",
       "       [19,  1,  6,  4,  7,  4,  2,  6,  9,  8, 10,  7, 14,  4,  8, 13,\n",
       "        12,  1,  6,  1,  3,  1,  4, 15,  4, 21, 15,  5, 19, 11,  3,  2],\n",
       "       [ 1,  3, 18,  1, 14,  6,  1,  8,  1,  1,  2, 10, 12, 22,  1,  7,\n",
       "         7,  8, 18, 17,  9,  3,  5,  4, 22,  4,  9,  3,  4,  1,  4,  1],\n",
       "       [ 9,  9,  2, 12,  1,  3, 16, 15,  4, 13,  4,  1, 11,  2, 16, 22,\n",
       "         6, 14,  1,  9,  1,  7,  6,  6,  2,  3,  7,  1,  6,  8,  6, 11]])>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7c34c523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(320,), dtype=int32, numpy=\n",
       "array([15, 21,  1, 10,  4,  4, 19,  3, 12,  5, 12, 20,  3, 19,  8,  7,  2,\n",
       "        4, 15,  9,  3, 18,  7, 12,  9,  7,  2, 19,  1, 10,  6, 13,  9, 14,\n",
       "       16,  4, 14,  6,  1,  7,  2,  7,  2, 10,  9,  7,  1, 17,  1, 10,  1,\n",
       "        2,  9,  7,  1,  2,  4, 16, 10,  2, 16,  1,  2,  3,  5, 21,  7,  3,\n",
       "       18,  1,  7, 14, 10, 14,  6,  7,  2, 14,  7,  8, 17,  2, 26, 10,  2,\n",
       "        1, 14, 10, 12,  1, 13,  8,  4,  9,  1,  9,  6, 21, 10,  9,  9,  5,\n",
       "       16, 10,  1,  8, 18, 16, 19,  1, 16,  1,  4,  1, 14,  2,  1, 21, 20,\n",
       "       19, 12,  3,  4,  1,  5,  2,  8,  2,  2, 12,  2,  2,  3,  6,  1,  1,\n",
       "       17,  6,  3,  2,  1,  5,  1,  3,  8, 19, 13,  3,  2,  4,  1,  7,  1,\n",
       "        9,  6,  8,  6,  1, 14,  6,  1,  2, 16, 10,  1,  8,  3, 15,  5,  2,\n",
       "        9,  8, 15,  1,  9,  9,  1,  7, 20,  9,  4, 15,  4, 14,  3,  2,  1,\n",
       "        7,  3,  9, 21,  1, 21,  8,  5,  1, 19,  3,  9,  7,  3,  8, 21,  8,\n",
       "        7,  9,  5,  2,  4, 14,  5,  2, 10, 23, 18,  1, 10,  1,  8,  1, 12,\n",
       "        4,  8,  9, 19,  1,  6,  4,  7,  4,  2,  6,  9,  8, 10,  7, 14,  4,\n",
       "        8, 13, 12,  1,  6,  1,  3,  1,  4, 15,  4, 21, 15,  5, 19, 11,  3,\n",
       "        2,  1,  3, 18,  1, 14,  6,  1,  8,  1,  1,  2, 10, 12, 22,  1,  7,\n",
       "        7,  8, 18, 17,  9,  3,  5,  4, 22,  4,  9,  3,  4,  1,  4,  1,  9,\n",
       "        9,  2, 12,  1,  3, 16, 15,  4, 13,  4,  1, 11,  2, 16, 22,  6, 14,\n",
       "        1,  9,  1,  7,  6,  6,  2,  3,  7,  1,  6,  8,  6, 11])>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(tf.transpose(Y), (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2939f22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time traveller held in hing that is jelinctime se have not said t'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = predict('time traveller ', net, 50, vocab)\n",
    "\n",
    "''.join([vocab.idx_to_token[i] for i in O])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9f4dd286",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = net.begin_state(batch_size=X.shape[0])\n",
    "X = tf.one_hot(X, len(vocab)) # (batch_size, num_steps, vocab_size)\n",
    "X = tf.transpose(X, perm=[1, 0, 2]) # (num_steps, batch_size, vocab_size)\n",
    "y_hat, s = net(X, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "658a02cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([320, 28])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "61a97288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 32, 28])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c037d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
